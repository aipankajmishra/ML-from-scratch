{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN.ipnb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPLFReyLrIlVcIr7Nyd7TFY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aipankajmishra/ML-from-scratch/blob/master/KNN_ipnb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imporing libraries"
      ],
      "metadata": {
        "id": "6A48ZYreo0tZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris,load_boston\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "0aWHGoGGo_4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Utility functions**"
      ],
      "metadata": {
        "id": "1QA4HmrR8Xnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def most_common_element(lst):\n",
        "\treturn max(set(lst),key = lst.count)\n",
        "\n",
        "def euclidean_distance(test_instance, train_instance):\n",
        "\t_sum = np.sum([(val - train_instance[idx])**2 for idx,val in enumerate(test_instance)])\n",
        "\treturn np.sqrt(_sum)\n",
        "\n",
        "def accuracy_score(ypred, y_test):\n",
        "\treturn (np.sum(ypred == y_test)/len(y_test))"
      ],
      "metadata": {
        "id": "EX2wt9Qi8WNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KNN:\n",
        "\n",
        "\tdef __init__(self,k = 3):\n",
        "\t\tself.k = k \n",
        "\n",
        "\tdef fit(self, X, y):\n",
        "\t\tself.X_train = X\n",
        "\t\tself.y_train = y \n",
        "\n",
        "\n",
        "\tdef label_assign(self, closest_k):\n",
        "\t\tcommon_label = most_common_element(self.y_train[closest_k].tolist())\n",
        "\t\treturn common_label\n",
        "\n",
        "\n",
        "\tdef _predict(self, x):\n",
        "\t\t\n",
        "\t\t\"\"\"\n",
        "\t\t\tThis method returns output for a single instace.\n",
        "\t\t\tWe will call this method for all instance in X_test\n",
        "\t\t\t\n",
        "\t\t\tCalculate distance of this instance from all other in the training set. \n",
        "\t\t\tAfter calculating the distance, we will select the closest k from the given sample.\n",
        "\n",
        "\t\t\tAfter that, we will vote and get the value which is in the majority.\n",
        "\t\t\"\"\"\n",
        "\n",
        "\t\tdistances = []\n",
        "\n",
        "\t\tfor i, train_record in enumerate(self.X_train):\n",
        "\t\t\teucl_distance =  euclidean_distance(x,train_record)\n",
        "\t\t\tdistances.append(eucl_distance)\n",
        "\n",
        "\t\t\"\"\" \n",
        "\t\tNow we have calculated the euclidean distance of the instance from each  sample in the train, \n",
        "\t\twe will try labelling it using the closes k neighbor's label. \n",
        "\t\t\"\"\"\n",
        "\t\tclosest_k = np.argsort(distances)[:self.k]\n",
        "\t\t\n",
        "\t\tassign_label = self.label_assign(closest_k)\n",
        "\t\treturn assign_label\n",
        "\n",
        "\n",
        "\tdef predict(self, X_test):\n",
        "\t\treturn np.asarray([self._predict(x) for x in X_test])"
      ],
      "metadata": {
        "id": "_ze7e7i38OeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  print(\"Running the KNN algorithm implementation from scratch\")\n",
        "\n",
        "  # Loading the dataset, we will use KNN for solving a classification problem\n",
        "\n",
        "  X, y = load_iris(return_X_y = True)\n",
        "\n",
        "  # Now dividing the dataset we got into the train and test\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.33, random_state = 42)\n",
        "\n",
        "  \"\"\"\n",
        "    Now we have the split, lets call the KNN implementation to fit the train data and have the predictions\n",
        "  \"\"\"\n",
        "\n",
        "  clf = KNN(k = 10)\n",
        "\n",
        "  clf.fit(X_train,y_train)\n",
        "\n",
        "  ypred = clf.predict(X_test)\n",
        "\n",
        "  print(\"The predictions are - \")\n",
        "  print(ypred)\n",
        "\n",
        "  print(\"The accuracy is - \")\n",
        "  accuracy = accuracy_score(ypred,y_test)\n",
        "  print(accuracy)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\tmain()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcObYEWbo2w3",
        "outputId": "92c1c10f-fe27-4410-b174-c97b2ec6a762"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running the KNN algorithm implementation from scratch\n",
            "[[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]]\n",
            "The predictions are - \n",
            "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
            " 0 0 0 2 1 1 0 0 1 1 2 1 2]\n",
            "The accuracy is - \n",
            "0.98\n"
          ]
        }
      ]
    }
  ]
}