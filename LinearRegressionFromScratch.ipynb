{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LinearRegressionFromScratch",
      "provenance": [],
      "authorship_tag": "ABX9TyO3IIj7UnaO27CRGtDC5/l0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aipankajmishra/ML-from-scratch/blob/master/LinearRegressionFromScratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Imporing libraries**"
      ],
      "metadata": {
        "id": "6A48ZYreo0tZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris,load_boston, load_diabetes\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import linear_model"
      ],
      "metadata": {
        "id": "0aWHGoGGo_4r"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Utility functions**"
      ],
      "metadata": {
        "id": "1QA4HmrR8Xnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cost_function_rmse(P,Y):\n",
        "  return np.sqrt(np.mean((P-Y)**2))\n",
        "\n",
        "def add_constant_bias(X):\n",
        "  return np.c_[np.ones(len(X)),X]\n",
        "\n",
        "def predictions(X,weights):\n",
        "  return np.matmul(X,weights)\n",
        "\n",
        "def gradient_descent(X,y,weights):\n",
        "  weights = weights.reshape(-1,1)\n",
        "  P = predictions(X,weights)\n",
        "  m = len(X)\n",
        "  Y = y.reshape(-1,1)\n",
        "  err = (P - Y)\n",
        "  grad = -1 * (2/m) * np.matmul(err.T,X)\n",
        "  return grad.T"
      ],
      "metadata": {
        "id": "VXjsuxskE27s"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegression():\n",
        "\n",
        "  def __init__(self,learning_rate,epochs):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.n_iters = epochs\n",
        "\n",
        "  def fit(self,X,y):\n",
        "    # Add the constant bias term to our X.\n",
        "    X = add_constant_bias(X)\n",
        "\n",
        "    epochs = self.n_iters\n",
        "    learning_rate = self.learning_rate \n",
        "\n",
        "    # Initializing initial weights with Zeros\n",
        "    weights = np.zeros(X.shape[1]).reshape(-1,1)\n",
        "    for iter in range(epochs):\n",
        "      grad_descent = gradient_descent(X,y,weights)\n",
        "      weights = weights - learning_rate*grad_descent\n",
        "    \n",
        "    self.final_weights = weights\n",
        "  \n",
        "  def predict(self,X_test):\n",
        "    # Add bias to X_test too.\n",
        "    X_test = add_constant_bias(X_test)\n",
        "    return np.matmul(X_test,self.final_weights)"
      ],
      "metadata": {
        "id": "jQjXBn8XDRos"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  print(\"Running the Linear Regression algorithm implementation from scratch\")\n",
        "\n",
        "  # Loading the dataset, we will use LR for solving the regression problem\n",
        "\n",
        "  X,y = load_diabetes(return_X_y = True)\n",
        "  # Now dividing the dataset we got into the train and test\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.33, random_state = 42)\n",
        "\n",
        "  \"\"\"\n",
        "    Now we have the split, lets call the LinearRegression implementation to fit the train data and have the output\n",
        "  \"\"\"\n",
        "\n",
        "  clf = LinearRegression(learning_rate = 0.0001, epochs = 1000)\n",
        "\n",
        "  clf.fit(X_train,y_train)\n",
        "  ypred = clf.predict(X_test)\n",
        "  rmse_score = cost_function_rmse(ypred,y_test)\n",
        "  print(\"The rmse score is -\",rmse_score)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\tmain()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_w3iUAyEeCV",
        "outputId": "c3d2432e-4f97-40a5-89a6-84b442a84692"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running the Linear Regression algorithm implementation from scratch\n",
            "The rmse score is - 200.9494620891776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FmcLZQCjvwns"
      },
      "execution_count": 67,
      "outputs": []
    }
  ]
}